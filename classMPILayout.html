<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Gyselalib++: MPILayout&lt; IdxRangeData, DistributedDim &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">Gyselalib++
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classMPILayout.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classMPILayout-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">MPILayout&lt; IdxRangeData, DistributedDim &gt; Class Template Reference</div></div>
</div><!--header-->
<div class="contents">

<p>A class describing a way in which data may be laid out across MPI processes.  
 <a href="classMPILayout.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for MPILayout&lt; IdxRangeData, DistributedDim &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classMPILayout.png" usemap="#MPILayout_3C_20IdxRangeData_2C_20DistributedDim_20_3E_map" alt=""/>
  <map id="MPILayout_3C_20IdxRangeData_2C_20DistributedDim_20_3E_map" name="MPILayout_3C_20IdxRangeData_2C_20DistributedDim_20_3E_map">
<area href="classIMPILayout.html" alt="IMPILayout&lt; IdxRangeData, DistributedDim... &gt;" shape="rect" coords="0,0,279,24"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:ad8142e0f533a266313e76614698b2ccc" id="r_ad8142e0f533a266313e76614698b2ccc"><td class="memItemLeft" align="right" valign="top"><a id="ad8142e0f533a266313e76614698b2ccc" name="ad8142e0f533a266313e76614698b2ccc"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>idx_range_type</b> = IdxRangeData</td></tr>
<tr class="memdesc:ad8142e0f533a266313e76614698b2ccc"><td class="mdescLeft">&#160;</td><td class="mdescRight">The index range of the data. <br /></td></tr>
<tr class="separator:ad8142e0f533a266313e76614698b2ccc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5c0300b226356271de45722fcc7f447" id="r_ad5c0300b226356271de45722fcc7f447"><td class="memItemLeft" align="right" valign="top"><a id="ad5c0300b226356271de45722fcc7f447" name="ad5c0300b226356271de45722fcc7f447"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>distributed_sub_idx_range</b> = typename <a class="el" href="classIMPILayout.html#affaed5e5e8eba26de6e64662c6ebc7d7">base_type::distributed_sub_idx_range</a></td></tr>
<tr class="memdesc:ad5c0300b226356271de45722fcc7f447"><td class="mdescLeft">&#160;</td><td class="mdescRight">The index range of the distributed section of the data. <br /></td></tr>
<tr class="separator:ad5c0300b226356271de45722fcc7f447"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a802925fc2fae468337b971b46f769500" id="r_a802925fc2fae468337b971b46f769500"><td class="memItemLeft" align="right" valign="top"><a id="a802925fc2fae468337b971b46f769500" name="a802925fc2fae468337b971b46f769500"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>distributed_type_seq</b> = typename <a class="el" href="classIMPILayout.html#a5734be7b4782cfd49498bd2ad6610353">base_type::distributed_type_seq</a></td></tr>
<tr class="memdesc:a802925fc2fae468337b971b46f769500"><td class="mdescLeft">&#160;</td><td class="mdescRight">A type sequence describing the dimensions which are distributed across MPI processes. <br /></td></tr>
<tr class="separator:a802925fc2fae468337b971b46f769500"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classIMPILayout"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classIMPILayout')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classIMPILayout.html">IMPILayout&lt; IdxRangeData, DistributedDim... &gt;</a></td></tr>
<tr class="memitem:aa958ea8d8ed3431a7d14e0333e379566 inherit pub_types_classIMPILayout" id="r_aa958ea8d8ed3431a7d14e0333e379566"><td class="memItemLeft" align="right" valign="top">
using&#160;</td><td class="memItemRight" valign="bottom"><b>discrete_domain_type</b> = IdxRangeData</td></tr>
<tr class="memdesc:aa958ea8d8ed3431a7d14e0333e379566 inherit pub_types_classIMPILayout"><td class="mdescLeft">&#160;</td><td class="mdescRight">The index range of the data. <br /></td></tr>
<tr class="separator:aa958ea8d8ed3431a7d14e0333e379566 inherit pub_types_classIMPILayout"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affaed5e5e8eba26de6e64662c6ebc7d7 inherit pub_types_classIMPILayout" id="r_affaed5e5e8eba26de6e64662c6ebc7d7"><td class="memItemLeft" align="right" valign="top">
using&#160;</td><td class="memItemRight" valign="bottom"><b>distributed_sub_idx_range</b> = IdxRange&lt; DistributedDim... &gt;</td></tr>
<tr class="memdesc:affaed5e5e8eba26de6e64662c6ebc7d7 inherit pub_types_classIMPILayout"><td class="mdescLeft">&#160;</td><td class="mdescRight">The index range of the distributed section of the data. <br /></td></tr>
<tr class="separator:affaed5e5e8eba26de6e64662c6ebc7d7 inherit pub_types_classIMPILayout"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5734be7b4782cfd49498bd2ad6610353 inherit pub_types_classIMPILayout" id="r_a5734be7b4782cfd49498bd2ad6610353"><td class="memItemLeft" align="right" valign="top">
using&#160;</td><td class="memItemRight" valign="bottom"><b>distributed_type_seq</b> = ddc::detail::TypeSeq&lt; DistributedDim... &gt;</td></tr>
<tr class="memdesc:a5734be7b4782cfd49498bd2ad6610353 inherit pub_types_classIMPILayout"><td class="mdescLeft">&#160;</td><td class="mdescRight">A type sequence describing the dimensions which are distributed across MPI processes. <br /></td></tr>
<tr class="separator:a5734be7b4782cfd49498bd2ad6610353 inherit pub_types_classIMPILayout"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:af33d3fc6e12f1505f769d32fd8d293c6" id="r_af33d3fc6e12f1505f769d32fd8d293c6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classMPILayout.html#ad8142e0f533a266313e76614698b2ccc">idx_range_type</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMPILayout.html#af33d3fc6e12f1505f769d32fd8d293c6">distribute_idx_range</a> (<a class="el" href="classMPILayout.html#ad8142e0f533a266313e76614698b2ccc">idx_range_type</a> global_idx_range, int comm_size, int rank)</td></tr>
<tr class="memdesc:af33d3fc6e12f1505f769d32fd8d293c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the distributed index range which follows the chosen layout.  <br /></td></tr>
<tr class="separator:af33d3fc6e12f1505f769d32fd8d293c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a6f9deb749c456a6c7a8fbccb10f35bd6" id="r_a6f9deb749c456a6c7a8fbccb10f35bd6"><td class="memTemplParams" colspan="2">template&lt;class HeadTag &gt; </td></tr>
<tr class="memitem:a6f9deb749c456a6c7a8fbccb10f35bd6"><td class="memTemplItemLeft" align="right" valign="top">IdxRange&lt; HeadTag &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classMPILayout.html#a6f9deb749c456a6c7a8fbccb10f35bd6">internal_distribute_idx_range</a> (IdxRange&lt; HeadTag &gt; global_idx_range, int comm_size, int rank)</td></tr>
<tr class="memdesc:a6f9deb749c456a6c7a8fbccb10f35bd6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Distribute a 1D index range over the MPI processes.  <br /></td></tr>
<tr class="separator:a6f9deb749c456a6c7a8fbccb10f35bd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad73e8704d2db772bd557acb1876f0b02" id="r_ad73e8704d2db772bd557acb1876f0b02"><td class="memTemplParams" colspan="2">template&lt;class HeadTag , class... Tags, std::enable_if_t&lt;(sizeof...(Tags) &gt; 0), bool &gt;  = true&gt; </td></tr>
<tr class="memitem:ad73e8704d2db772bd557acb1876f0b02"><td class="memTemplItemLeft" align="right" valign="top">IdxRange&lt; HeadTag, Tags... &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classMPILayout.html#ad73e8704d2db772bd557acb1876f0b02">internal_distribute_idx_range</a> (IdxRange&lt; HeadTag, Tags... &gt; idx_range, int comm_size, int rank)</td></tr>
<tr class="memdesc:ad73e8704d2db772bd557acb1876f0b02"><td class="mdescLeft">&#160;</td><td class="mdescRight">Distribute the index range over the MPI processes.  <br /></td></tr>
<tr class="separator:ad73e8704d2db772bd557acb1876f0b02"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pub_static_attribs_classIMPILayout"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classIMPILayout')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classIMPILayout.html">IMPILayout&lt; IdxRangeData, DistributedDim... &gt;</a></td></tr>
<tr class="memitem:ab55757fa0972d849a94feeca30a9f465 inherit pub_static_attribs_classIMPILayout" id="r_ab55757fa0972d849a94feeca30a9f465"><td class="memItemLeft" align="right" valign="top">
static constexpr int&#160;</td><td class="memItemRight" valign="bottom"><b>n_distributed_dimensions</b></td></tr>
<tr class="memdesc:ab55757fa0972d849a94feeca30a9f465 inherit pub_static_attribs_classIMPILayout"><td class="mdescLeft">&#160;</td><td class="mdescRight">The number of dimensions that are distributed across MPI processes. <br /></td></tr>
<tr class="separator:ab55757fa0972d849a94feeca30a9f465 inherit pub_static_attribs_classIMPILayout"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab14961802d15d51c8a1a45c7896e64d inherit pub_static_attribs_classIMPILayout" id="r_aab14961802d15d51c8a1a45c7896e64d"><td class="memItemLeft" align="right" valign="top">
static constexpr bool&#160;</td><td class="memItemRight" valign="bottom"><b>distributed_idx_ranges_are_first</b></td></tr>
<tr class="memdesc:aab14961802d15d51c8a1a45c7896e64d inherit pub_static_attribs_classIMPILayout"><td class="mdescLeft">&#160;</td><td class="mdescRight">A flag to indicate whether the distributed dimensions are the dimensions which are the furthest from being contiguous in memory. <br /></td></tr>
<tr class="separator:aab14961802d15d51c8a1a45c7896e64d inherit pub_static_attribs_classIMPILayout"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><div class="compoundTemplParams">template&lt;class IdxRangeData, class... DistributedDim&gt;<br />
class MPILayout&lt; IdxRangeData, DistributedDim &gt;</div><p>A class describing a way in which data may be laid out across MPI processes. </p>
<p>This class describes the simplest way of laying out data. In this layout the data is distributed along dimensions in order until the data is distributed. It is possible that the data may not be distributed along some of the requested dimensions if such distribution is not necessary. For example if we distribute dimensions <a class="el" href="structR.html" title="Define non periodic real contravariant R dimension.">R</a> and <a class="el" href="structTheta.html" title="Define periodic real contravariant Theta dimension.">Theta</a> of a (<a class="el" href="structR.html" title="Define non periodic real contravariant R dimension.">R</a>, <a class="el" href="structTheta.html" title="Define periodic real contravariant Theta dimension.">Theta</a>, Phi, <a class="el" href="structVpar.html" title="Define non periodic parallel velocity .">Vpar</a>, <a class="el" href="structMu.html" title="Define non periodic magnetic momentum .">Mu</a>) grid of size 256 x 1024 x 256 x 64 x 8 over 64 processes, the theta dimension will not be distributed.</p>
<p>The data is distributed such that it is maximally distributed over each dimension (in order) such that the size of each local index range along that dimension is the same for all processes. For example if we distribute dimensions <a class="el" href="structX.html" title="Define non periodic real X dimension.">X</a> and <a class="el" href="structY.html" title="Define non periodic real Y dimension.">Y</a> of a (<a class="el" href="structX.html" title="Define non periodic real X dimension.">X</a>, <a class="el" href="structY.html" title="Define non periodic real Y dimension.">Y</a>, Z) grid of size (10, 15, 4) over 6 processes, the <a class="el" href="structX.html" title="Define non periodic real X dimension.">X</a> dimension will be distributed over 2 processes and the <a class="el" href="structY.html" title="Define non periodic real Y dimension.">Y</a> dimension will be distributed over 3 processes.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">IdxRangeData</td><td>The IdxRange on which the data is defined. </td></tr>
    <tr><td class="paramname">DistributedDim</td><td>The tags of the discrete dimensions which are distributed across MPI processes. </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="af33d3fc6e12f1505f769d32fd8d293c6" name="af33d3fc6e12f1505f769d32fd8d293c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af33d3fc6e12f1505f769d32fd8d293c6">&#9670;&#160;</a></span>distribute_idx_range()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class IdxRangeData , class... DistributedDim&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMPILayout.html#ad8142e0f533a266313e76614698b2ccc">idx_range_type</a> <a class="el" href="classMPILayout.html">MPILayout</a>&lt; IdxRangeData, DistributedDim &gt;::distribute_idx_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classMPILayout.html#ad8142e0f533a266313e76614698b2ccc">idx_range_type</a>&#160;</td>
          <td class="paramname"><em>global_idx_range</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>comm_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the distributed index range which follows the chosen layout. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">global_idx_range</td><td>The global (non-distributed) index range. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">comm_size</td><td>The number of MPI processes over which the data is distributed. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rank</td><td>The rank of the current MPI process.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The distributed index range. </dd></dl>

</div>
</div>
<a id="a6f9deb749c456a6c7a8fbccb10f35bd6" name="a6f9deb749c456a6c7a8fbccb10f35bd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f9deb749c456a6c7a8fbccb10f35bd6">&#9670;&#160;</a></span>internal_distribute_idx_range() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class IdxRangeData , class... DistributedDim&gt; </div>
<div class="memtemplate">
template&lt;class HeadTag &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">IdxRange&lt; HeadTag &gt; <a class="el" href="classMPILayout.html">MPILayout</a>&lt; IdxRangeData, DistributedDim &gt;::internal_distribute_idx_range </td>
          <td>(</td>
          <td class="paramtype">IdxRange&lt; HeadTag &gt;&#160;</td>
          <td class="paramname"><em>global_idx_range</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>comm_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Distribute a 1D index range over the MPI processes. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">global_idx_range</td><td>The index range to be distributed. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">comm_size</td><td>The number of processes over which the data should be disctributed. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rank</td><td>The rank of the process within the current group of processes</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The distributed index range. </dd></dl>

</div>
</div>
<a id="ad73e8704d2db772bd557acb1876f0b02" name="ad73e8704d2db772bd557acb1876f0b02"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad73e8704d2db772bd557acb1876f0b02">&#9670;&#160;</a></span>internal_distribute_idx_range() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class IdxRangeData , class... DistributedDim&gt; </div>
<div class="memtemplate">
template&lt;class HeadTag , class... Tags, std::enable_if_t&lt;(sizeof...(Tags) &gt; 0), bool &gt;  = true&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">IdxRange&lt; HeadTag, Tags... &gt; <a class="el" href="classMPILayout.html">MPILayout</a>&lt; IdxRangeData, DistributedDim &gt;::internal_distribute_idx_range </td>
          <td>(</td>
          <td class="paramtype">IdxRange&lt; HeadTag, Tags... &gt;&#160;</td>
          <td class="paramname"><em>idx_range</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>comm_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Distribute the index range over the MPI processes. </p>
<p>This function is called recursively. At each pass it distributes the index range over the first dimension in the discrete index range. The remaining dimensions and processes are then handled in the recursive call.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">idx_range</td><td>The index range to be distributed. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">comm_size</td><td>The number of processes over which the data should be disctributed. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rank</td><td>The rank of the process within the current group of processes</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The distributed index range. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/runner/work/gyselalibxx/gyselalibxx/code_branch/src/mpi_parallelisation/<a class="el" href="mpilayout_8hpp_source.html">mpilayout.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="classMPILayout.html">MPILayout</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
